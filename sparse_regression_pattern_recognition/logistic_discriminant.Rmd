---
title: "ロジスティック判別"
author: "Koya Ohashi"
date: 2023-12-21
output:
  html_document:
    code_folding: show
    toc: true
editor_options: 
  chunk_output_type: console
---

本資料は、書籍「[スパース回帰分析とパターン認識](https://www.kspub.co.jp/book/detail/5186206.html)」を筆者が勉強する過程で作成したものであり、詳細は当該書籍を参照されたい。

# ロジスティック判別とは？

## ベイズ判別ルール

まず前節までに導入されたベイズ判別ルールについて簡単に振り返る。詳細は[前回発表資料](https://tarohgotoh.github.io/DS-Study/)を参照されたい。

ベイズ判別ルールとは、統計的分類手法のひとつであり、各観測値が属する群（クラス）を判別する機能を持つ。具体的に2群分類の場合には、下記のルールにより観測空間を各群への帰属領域として分割する。

$$
\begin{aligned}
R_1 &= \{x \in R^d \mid \pi_2 f_2(x) \leq \pi_1 f_1(x) \} \\
R_2 &= \{x \in R^d \mid \pi_2 f_2(x) > \pi_1 f_1(x) \} 
\end{aligned} 
$$

ただし、各記号はそれぞれ

-   $x$ : 観測値

-   $\pi_k$ , $f_k$ : 母集団（群k, k=1,2）の事前確率、確率密度関数

を表す。このルールは、ベイズ事後確率の大小比較と等価のためベイズ判別ルールと呼ばれている。

ベイズ判別ルールにおいて重要な性質は、事後確率の比が分かれば十分ということである。つまり、

$$
\begin{aligned}
&\pi_2 f_2(x) \leq \pi_1 f_1(x) \\
\Leftrightarrow & 1 \leq \frac{\pi_1 f_1(x)}{\pi_2 f_2(x)}, \pi_2 f_2(x) \neq 0
\end{aligned}
$$

が成り立つ。任意の観測値 $x$ に対して各群での発生確率が0でないと仮定できれば、単純に事後確率の比が1を超えるか否かで判別ルールを定義できる。計算の都合上、両辺に対数を取ることもよく行われる。

さて、2群それぞれのサンプルが、共通の共分散行列を持つ2つの正規分布 $N(\mu_k, \Sigma)$ に従い発生していると仮定する。この場合の判別ルールは、対数密度比が
\begin{align}
\log \left\{ \frac{\pi_1 N(x \mid \mu_1, \Sigma)}{\pi_2 N(x \mid \mu_2, \Sigma)} \right\} &= (\Sigma^{-1}(\mu_1 - \mu_2))^\top x - \frac{1}{2}(\mu_1 - \mu_2)^\top \Sigma^{-1} (\mu_1 + \mu_2) + \log(\frac{\pi_1}{\pi_2}) \\
&= \nu^\top x + \xi
\end{align}

となるため、観測値 $x$ の一次結合で定義できる。 $x \in \mathbb{R}^d$ の場合、判別ルールは $d+1$ 個のパラメータが特定できれば十分（一意に定まる）とわかる。しかし、今回の例では $\mu_1, \mu_2, \Sigma$ に含まれるパラメータ数は合計 $d(d+3)/2 -1$ 個であり、必要以上にパラメータを推定している。観測空間の次元数 $d$ が大きいほど不要なパラメータ数も増大するため判別効率が下がってしまう。そのため、より多くの説明変数を加えたにも関わらず、期待通りに判別性能が向上するとは限らない。

```{r}
x <- seq(1, 50, 1)
plot(x, x+1, ylim = c(0, 1000), type = 'o', xlab = 'dim of observations', ylab='# of params')
par(new = T)
plot(x, x*(x+3)/2 - 1, ylim = c(0, 1000), type = 'o', pch = 0, ann = F)
```

## ロジスティック判別

自然な発想として、 $d+1$ 個のパラメータを直接推定したら効率的に思える。つまり、

$$
\begin{aligned}
\log \left\{ \frac{\pi_1 f_1(x)}{\pi_2 f_2(x)} \right\} &= \beta_0 + \beta^\top x
\end{aligned}
$$

を満たす分布族においては、直接パラメータ $\{\beta_0, \beta\}$ を推定することを考える。これを**ロジスティックモデル**と呼び、このモデルによる判別を**ロジスティック判別**と呼ぶ。

このロジスティックモデルが適応できる分布族は、以下が挙げられる。

1.  共分散行列が共通の正規分布
2.  各成分が独立なベルヌーイ分布に従う離散型分布
3.  1の混合分布、または2の混合分布

ここでは1,2への証明を与えたい。

### ロジスティックモデル：共分散行列が共通の正規分布

共分散行列が等しい場合は、 対数密度比が$x$ の一次結合となることは前節「[ベイズ判別ルール]」にて確認済みである。共分散行列が異なる場合は、二次項が残り二次判別となるためロジスティックモデルでは表現できない点に注意が必要である（テキストp.72参照）。

### ロジスティックモデル：各成分が独立なベルヌーイ分布に従う離散型分布

確率変数 $X = (X_1, X_2, \ldots, X_d)^\top$　の各成分が独立にベルヌーイ分布に従う場合、群 $k$ の確率関数は

$$
\begin{align}
f_k(x) = \prod_{i=1}^{d} p_{ki}^{x_i}(1-p_{ki})^{1-x_i}
\end{align}
$$

となる。このとき対数の確率関数比は

$$
\begin{align}
\log \left\{\frac{\pi_1 f_1(x)}{\pi_2 f_2(x)}\right\} &= \log \left\{\frac{\pi_1 \prod_{i=1}^{d} p_{1i}^{x_i}(1-p_{1i})^{1-x_i}}{\pi_2 \prod_{i=1}^{d} p_{2i}^{x_i}(1-p_{2i})^{1-x_i}}\right\} \\
&= \sum_{i=1}^{d}\left(x_i\log\frac{p_{1i}}{p_{2i}} + (1-x_i)\log\frac{1-p_{1i}}{1-p_{2i}} \right) + (\text{定数項}) \\
&= \sum_{i=1}^{d}\left(\log\frac{p_{1i}}{p_{2i}} - \log\frac{1-p_{1i}}{1-p_{2i}} \right)x_i + (\text{定数項})
\end{align}
$$

となり観測値 $x$ の一次結合で表せることがわかった。

観測値が1次元であり、群1の確率関数が $p$ 、群2の確率関数が $1-p$ の場合は

$$
\begin{align}
\log \frac{p}{1-p} = \beta_0 + \beta^\top x
\end{align}
$$

のようなモデルとなり二値分類が可能となる。他の教科書では、このように対数オッズ比の線形回帰にからロジスティックモデルを導入することが多いように思う。

パラメータは最尤推定法により推定可能である。詳細はテキストp.86に譲るが、ロジスティックモデルの対数尤度は2階微分が負の上に凸な関数であるため、ニュートン法により安定して（局所最適にトラップされることなく）最尤推定量を求められる。

# ロジスティック判別の性能評価実験

真の分布が正規分布だったときどうか？

次元数が多い時どうか？

他群判別のとき、ベースの取り方に依存するか？
